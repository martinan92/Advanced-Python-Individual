{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelBinarizer, \\\n",
    "    RobustScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, \\\n",
    "    ShuffleSplit, validation_curve, cross_validate, \\\n",
    "    train_test_split, KFold, cross_val_predict\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import skew, boxcox_normmax\n",
    "from sklearn.externals import joblib\n",
    "from dask.distributed import Client, progress\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "from dask import dataframe as dd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "client = Client(processes=False, threads_per_worker=4,\n",
    "                n_workers=1, memory_limit='2GB')\n",
    "client\n",
    "\n",
    "day_url = 's3://advancedpythonmartinan/day.csv'\n",
    "hour_url = 's3://advancedpythonmartinan/hour.csv'\n",
    "mykey = 'AKIAX4VZYXLOZ2KZLTHG'\n",
    "aws_secret_access_key = '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'\n",
    "\n",
    "original_day = dd.read_csv(day_url, storage_options={\n",
    "                           'key': mykey, 'secret': aws_secret_access_key})\n",
    "\n",
    "original_hour = dd.read_csv(hour_url, storage_options={\n",
    "                            'key': mykey, 'secret': aws_secret_access_key})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: describe, 82 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              instant season     yr   mnth holiday weekday workingday weathersit     temp    atemp      hum windspeed casual registered    cnt\n",
       "npartitions=1                                                                                                                                 \n",
       "                int64  int64  int64  int64   int64   int64      int64      int64  float64  float64  float64   float64  int64      int64  int64\n",
       "                  ...    ...    ...    ...     ...     ...        ...        ...      ...      ...      ...       ...    ...        ...    ...\n",
       "Dask Name: describe, 82 tasks"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_day_df=original_day.copy()\n",
    "raw_day_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: describe, 86 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              instant season     yr   mnth     hr holiday weekday workingday weathersit     temp    atemp      hum windspeed casual registered    cnt\n",
       "npartitions=1                                                                                                                                        \n",
       "                int64  int64  int64  int64  int64   int64   int64      int64      int64  float64  float64  float64   float64  int64      int64  int64\n",
       "                  ...    ...    ...    ...    ...     ...     ...        ...        ...      ...      ...      ...       ...    ...        ...    ...\n",
       "Dask Name: describe, 86 tasks"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hour_df=original_hour.copy()\n",
    "raw_hour_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hour_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 16 entries, instant to cnt\n",
      "dtypes: object(1), float64(4), int64(11)"
     ]
    }
   ],
   "source": [
    "raw_day_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 17 entries, instant to cnt\n",
      "dtypes: object(1), float64(4), int64(12)"
     ]
    }
   ],
   "source": [
    "raw_hour_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_day_df.isnull().values.any().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hour_df.isnull().values.any().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Checking for correctness in dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hour_df['dteday'] = dd.to_datetime(raw_hour_df.dteday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check if column 'mnth' corresponds to the month value from 'dteday' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(raw_hour_df['dteday'].dt.month.compute() == raw_hour_df['mnth'].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check if column 'yr' corresponds to the year values from 'dteday' column represented as binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_year = pd.Series(raw_hour_df['dteday'].dt.year.compute() == 2012)\n",
    "all(binary_year == raw_hour_df['yr'].astype('bool').compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a 'day' column that represents the day of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>7905</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>7906</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      instant     dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "7904     7905 2011-12-01       4   0    12   0        0        4           1   \n",
       "7905     7906 2011-12-01       4   0    12   1        0        4           1   \n",
       "\n",
       "      weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "7904           1  0.28  0.2576  0.52     0.3284       1          19   20  \n",
       "7905           1  0.26  0.2424  0.60     0.2836       1           9   10  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hour_df[(raw_hour_df.season == 4) & \n",
    "            (raw_hour_df.mnth == 12)].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining previous steps as function to later use in data preparation pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Data preparation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_types(df):\n",
    "    df[['season', 'mnth', 'weekday', 'weathersit']] = df[[\n",
    "        'season', 'mnth', 'weekday', 'weathersit']].astype('category')\n",
    "    df[['yr', 'holiday', 'workingday']] = df[[\n",
    "        'yr', 'holiday', 'workingday']].astype('uint8')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_skewness(df):\n",
    "    numeric_dtypes = ['float64']\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype in numeric_dtypes:\n",
    "            numeric_features.append(i)\n",
    "\n",
    "    feature_skew = df[numeric_features].apply(\n",
    "        lambda x: skew(x), axis=1).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew': feature_skew})\n",
    "    return feature_skew, numeric_features\n",
    "\n",
    "\n",
    "def fix_skewness(df):\n",
    "    feature_skew, numeric_features = feature_skewness(df)\n",
    "    high_skew = feature_skew[feature_skew > 0.5]\n",
    "    skew_index = high_skew.index\n",
    "\n",
    "    for i in skew_index:\n",
    "        df[i] = boxcox1p(df[i], boxcox_normmax(df[i]+1))\n",
    "\n",
    "    skew_features = df[numeric_features].apply(\n",
    "        lambda x: skew(x), axis=1).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew': skew_features})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_features(df):\n",
    "    columns = df.columns\n",
    "    return df._get_numeric_data().columns\n",
    "\n",
    "\n",
    "def categorical_features(df):\n",
    "    numerical_columns = numerical_features(df)\n",
    "    return(list(set(df.columns) - set(numerical_columns)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = MinMaxScaler().fit(raw_hour_df[['atemp', 'hum', 'windspeed']])\n",
    "raw_hour_df[['atemp', 'hum', 'windspeed']] = std_scale.transform(\n",
    "    raw_hour_df[['atemp', 'hum', 'windspeed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(df):\n",
    "    std_scale = MinMaxScaler().fit(df[['atemp', 'hum', 'windspeed']])\n",
    "    df[['atemp', 'hum', 'windspeed']] = std_scale.transform(\n",
    "        df[['atemp', 'hum', 'windspeed']])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_hour(df):\n",
    "    df[['hr']] = df[['hr']].astype('category')\n",
    "    df = onehot_encode(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    df = df.drop(['instant'], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def fix_wind(df):\n",
    "    wCol = [\"season\", \"weathersit\", \"hum\", \"mnth\", \"temp\", \"yr\", \"atemp\"]\n",
    "\n",
    "    dataWind0 = df[(df[\"windspeed\"] == 0).compute()]\n",
    "    dataWindNot0 = df[(df[\"windspeed\"] != 0).compute()]\n",
    "    dataWindNot0[\"windspeed\"] = dataWindNot0[\"windspeed\"].astype(\"str\")\n",
    "\n",
    "    with joblib.parallel_backend(\"dask\"):\n",
    "        rfModel_wind = RandomForestClassifier().fit(\n",
    "            dataWindNot0[wCol], dataWindNot0[\"windspeed\"])\n",
    "\n",
    "    wind0Values = dd.from_array(rfModel_wind.predict(X=dataWind0[wCol]))\n",
    "\n",
    "    dataWind0[\"windspeed\"] = wind0Values\n",
    "    df = dataWindNot0.append(dataWind0)\n",
    "    df[\"windspeed\"] = df[\"windspeed\"].astype(\"float\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', inplace=True, axis=1)\n",
    "\n",
    "    df = df.sort_values(by=['dteday', 'hr']).reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_fixed = fix_types(fix_skewness(standardize_data(drop_columns(fix_wind(raw_hour_df)))))\n",
    "#dataset_fixed = fix_types(fix_skewness(standardize_data(drop_columns(raw_hour_df))))\n",
    "dataset_fixed = fix_types(standardize_data(drop_columns(raw_hour_df)))\n",
    "\n",
    "# dataset_encoded=onehot_encode(dataset_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dteday season  yr mnth  hr  holiday weekday  workingday weathersit  \\\n",
       "0 2011-01-01      1   0    1   0        0       6           0          1   \n",
       "1 2011-01-01      1   0    1   1        0       6           0          1   \n",
       "2 2011-01-01      1   0    1   2        0       6           0          1   \n",
       "3 2011-01-01      1   0    1   3        0       6           0          1   \n",
       "4 2011-01-01      1   0    1   4        0       6           0          1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 17 entries, instant to cnt\n",
      "dtypes: datetime64[ns](1), float64(4), int64(12)"
     ]
    }
   ],
   "source": [
    "raw_hour_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c26641630>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For demonstration purposes, a sample is taken from the dask dataframe\n",
    "dataset_fixed_bins = dataset_fixed.sample(frac=0.1, replace=True).compute()\n",
    "dataset_fixed_bins.windspeed.hist(bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Understand the pattern of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py:2284: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `apply`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nValueError(\"time data 'foo' does not match format '%Y-%m-%d'\")\n\nTraceback:\n---------\n  File \"/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\", line 160, in raise_on_meta_error\n    yield\n  File \"/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\", line 3683, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/anaconda3/lib/python3.7/site-packages/dask/utils.py\", line 697, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 3194, in apply\n    mapped = lib.map_infer(values, f, convert=convert_dtype)\n  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n  File \"<ipython-input-73-8701d7767b25>\", line 14, in <lambda>\n    lambda dateString: calendar.day_name[datetime.strptime(dateString, \"%Y-%m-%d\").weekday()])\n  File \"/anaconda3/lib/python3.7/_strptime.py\", line 577, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/anaconda3/lib/python3.7/_strptime.py\", line 359, in _strptime\n    (data_string, format))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3682\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'udf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3683\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/dask/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-8701d7767b25>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(dateString)\u001b[0m\n\u001b[1;32m     13\u001b[0m hour[\"name_weekday\"] = hour.dteday.apply(\n\u001b[0;32m---> 14\u001b[0;31m     lambda dateString: calendar.day_name[datetime.strptime(dateString, \"%Y-%m-%d\").weekday()])\n\u001b[0m\u001b[1;32m     15\u001b[0m hour[\"name_month\"] = hour.dteday.apply(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    576\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    358\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0;32m--> 359\u001b[0;31m                          (data_string, format))\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data 'foo' does not match format '%Y-%m-%d'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-8701d7767b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m hour[\"name_weekday\"] = hour.dteday.apply(\n\u001b[0;32m---> 14\u001b[0;31m     lambda dateString: calendar.day_name[datetime.strptime(dateString, \"%Y-%m-%d\").weekday()])\n\u001b[0m\u001b[1;32m     15\u001b[0m hour[\"name_month\"] = hour.dteday.apply(\n\u001b[1;32m     16\u001b[0m     lambda dateString: calendar.month_name[datetime.strptime(dateString, \"%Y-%m-%d\").month])\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, meta, args, **kwds)\u001b[0m\n\u001b[1;32m   2286\u001b[0m             meta = _emulate(M.apply, self._meta_nonempty, func,\n\u001b[1;32m   2287\u001b[0m                             \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2288\u001b[0;31m                             args=args, udf=True, **kwds)\n\u001b[0m\u001b[1;32m   2289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m         return map_partitions(M.apply, self, func,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m_emulate\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3681\u001b[0m     \"\"\"\n\u001b[1;32m   3682\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mraise_on_meta_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'udf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3683\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_extract_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \"{2}\")\n\u001b[1;32m    176\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" in `{0}`\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `apply`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nValueError(\"time data 'foo' does not match format '%Y-%m-%d'\")\n\nTraceback:\n---------\n  File \"/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py\", line 160, in raise_on_meta_error\n    yield\n  File \"/anaconda3/lib/python3.7/site-packages/dask/dataframe/core.py\", line 3683, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/anaconda3/lib/python3.7/site-packages/dask/utils.py\", line 697, in __call__\n    return getattr(obj, self.method)(*args, **kwargs)\n  File \"/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\", line 3194, in apply\n    mapped = lib.map_infer(values, f, convert=convert_dtype)\n  File \"pandas/_libs/src/inference.pyx\", line 1472, in pandas._libs.lib.map_infer\n  File \"<ipython-input-73-8701d7767b25>\", line 14, in <lambda>\n    lambda dateString: calendar.day_name[datetime.strptime(dateString, \"%Y-%m-%d\").weekday()])\n  File \"/anaconda3/lib/python3.7/_strptime.py\", line 577, in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n  File \"/anaconda3/lib/python3.7/_strptime.py\", line 359, in _strptime\n    (data_string, format))\n"
     ]
    }
   ],
   "source": [
    "# Load the data again\n",
    "import warnings\n",
    "import tkinter\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "hour = dd.read_csv(hour_url, storage_options={\n",
    "                   'key': mykey, 'secret': aws_secret_access_key})\n",
    "\n",
    "# Split label the weekday and months based on the calendar\n",
    "\n",
    "hour[\"name_weekday\"] = hour.dteday.apply(\n",
    "    lambda dateString: calendar.day_name[datetime.strptime(dateString, \"%Y-%m-%d\").weekday()])\n",
    "hour[\"name_month\"] = hour.dteday.apply(\n",
    "    lambda dateString: calendar.month_name[datetime.strptime(dateString, \"%Y-%m-%d\").month])\n",
    "\n",
    "# Split the date to year, month, and day\n",
    "# Recreate the dataframe\n",
    "hour['date'] = hour['dteday']\n",
    "hour.date = dd.to_datetime(hour.date)\n",
    "\n",
    "# Create 3 new columns for year, month, and day\n",
    "hour[['year', 'month', 'day']] = hour.date.apply(\n",
    "    lambda x: pd.Series(x.strftime(\"%Y,%m,%d\").split(\",\")))\n",
    "\n",
    "hour['hour'] = hour['hr']\n",
    "\n",
    "hour_dask = dd.from_pandas(hour, npartitions=3)\n",
    "\n",
    "# Import additional libraries\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"white\")\n",
    "sns.despine(fig=None)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# fig.set_size_inches(15,40)\n",
    "sortOrder = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "             \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "hueOrder = [\"Sunday\", \"Monday\", \"Tuesday\",\n",
    "            \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Understanding number of bike use based on month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average # of bikers\n",
    "from dask.dataframe.utils import make_meta\n",
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "monthAggregated = (hour_dask.groupby(\"name_month\")[\"cnt\"].mean()).reset_index()\n",
    "monthSorted = monthAggregated.compute().sort_values(by=\"cnt\", ascending=False)\n",
    "figure = sns.barplot(data=monthSorted, x=\"name_month\",\n",
    "                     y=\"cnt\", order=sortOrder)\n",
    "figure.set(xlabel='Month', ylabel='Average # of bikers',\n",
    "           title=\"Average Count By Month\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Understand number of bike use based on season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Users Count By Hour Of The Day Across Season\n",
    "plt.figure(figsize=(13, 5))\n",
    "hourAggregated = (hour_dask.groupby([\"hour\", \"season\"])[\n",
    "                  \"cnt\"].mean()).reset_index()\n",
    "hourAggregated = hourAggregated.compute().sort_values(by=\"cnt\", ascending=False)\n",
    "figure = sns.lineplot(x=hourAggregated[\"hour\"],\n",
    "                      y=hourAggregated[\"cnt\"],\n",
    "                      hue=hourAggregated[\"season\"],\n",
    "                      data=hourAggregated)\n",
    "figure.set(xlabel='Hour Of The Day',\n",
    "           ylabel='Avearage # of bikers',\n",
    "           title=\"Average Users Count By Hour Of The Day Across Season\",\n",
    "           label='big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Understand number of bike use based on Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Users Count By Hour Of The Day Across Weekdays\n",
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "hourAggregated = (hour_dask.groupby([\"hour\", \"name_weekday\"])[\n",
    "                  \"cnt\"].mean()).reset_index()\n",
    "hourAggregated = hourAggregated.compute().sort_values(by=\"cnt\", ascending=False)\n",
    "figure = sns.lineplot(x=hourAggregated[\"hour\"],\n",
    "                      y=hourAggregated[\"cnt\"],\n",
    "                      hue=hourAggregated[\"name_weekday\"], hue_order=hueOrder,\n",
    "                      data=hourAggregated)\n",
    "figure.set(xlabel='Hour Of The Day',\n",
    "           ylabel='Avearage # of bikers',\n",
    "           title=\"Average Users Count By Hour Of The Day Across Weekdays\",\n",
    "           label='big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Understand number of bike use based on user types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Users Count By Hour Of The Day Across User Type\n",
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "hourTransformed = dd.melt(hour_dask[[\"hour\", \"casual\", \"registered\"]], id_vars=[\n",
    "                          'hour'], value_vars=['casual', 'registered'])\n",
    "hourAggregated = (hourTransformed.groupby(\n",
    "    [\"hour\", \"variable\"])[\"value\"].mean()).reset_index()\n",
    "hourAggregated = hourAggregated.compute().sort_values(by=\"value\", ascending=False)\n",
    "figure = sns.lineplot(x=hourAggregated[\"hour\"],\n",
    "                      y=hourAggregated[\"value\"],\n",
    "                      hue=hourAggregated[\"variable\"],\n",
    "                      hue_order=[\"casual\", \"registered\"],\n",
    "                      data=hourAggregated)\n",
    "figure.set(xlabel='Hour Of The Day',\n",
    "           ylabel='Avearage # of bikers',\n",
    "           title=\"Average Users Count By Hour Of The Day Across User Type\",\n",
    "           label='big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Understand casual user pattern based on workingday and the hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Users Count By Hour Of The Day Across Weekdays\n",
    "hour_dask['name_workingday'] = hour_dask['workingday']\n",
    "hour_dask['name_workingday'] = hour_dask['name_workingday'].mask(\n",
    "    hour_dask['name_workingday'] == 0, 'dayOff')\n",
    "hour_dask['name_workingday'] = hour_dask['name_workingday'].mask(\n",
    "    hour_dask['name_workingday'] == 1, 'workingDay')\n",
    "\n",
    "hueOrder_2 = [\"dayOff\", \"workingDay\"]\n",
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "hourAggregated = (hour_dask.groupby([\"hour\", \"name_workingday\"])[\n",
    "                  \"casual\"].mean()).reset_index()\n",
    "hourAggregated = hourAggregated.compute().sort_values(by=\"casual\", ascending=False)\n",
    "figure = sns.lineplot(x=hourAggregated[\"hour\"],\n",
    "                      y=hourAggregated[\"casual\"],\n",
    "                      hue=hourAggregated[\"name_workingday\"],\n",
    "                      hue_order=hueOrder_2,\n",
    "                      data=hourAggregated)\n",
    "figure.set(xlabel='Hour Of The Day',\n",
    "           ylabel='Casual bikers',\n",
    "           title=\"Average Casual Users Count By Hour Of The Day Across Weekdays\",\n",
    "           label='big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Understand registered user pattern based on workingday and the hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Users Count By Hour Of The Day Across Weekdays\n",
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "hourAggregated = (hour_dask.groupby([\"hour\", \"name_workingday\"])[\n",
    "                  \"registered\"].mean()).reset_index()\n",
    "hourAggregated = hourAggregated.compute().sort_values(\n",
    "    by=\"registered\", ascending=False)\n",
    "figure = sns.lineplot(x=hourAggregated[\"hour\"],\n",
    "                      y=hourAggregated[\"registered\"],\n",
    "                      hue=hourAggregated[\"name_workingday\"],\n",
    "                      hue_order=hueOrder_2,\n",
    "                      data=hourAggregated)\n",
    "figure.set(xlabel='Hour Of The Day',\n",
    "           ylabel='Registered bikers',\n",
    "           title=\"Average Registered Users Count By Hour Of The Day Across Weekdays\",\n",
    "           label='big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Box plot to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "# For demonstration purposes, a sample is taken from the dask dataframe\n",
    "hour_box = hour_dask.sample(frac=0.1, replace=True).compute()\n",
    "\n",
    "sns.boxplot(data=hour_box, y=\"cnt\", orient=\"v\", ax=axes[0][0])\n",
    "sns.boxplot(data=hour_box, y=\"cnt\", x=\"season\", orient=\"v\", ax=axes[0][1])\n",
    "sns.boxplot(data=hour_box, y=\"cnt\", x=\"weekday\", orient=\"v\", ax=axes[1][0])\n",
    "sns.boxplot(data=hour_box, y=\"cnt\", x=\"workingday\", orient=\"v\", ax=axes[1][1])\n",
    "\n",
    "axes[0][0].set(ylabel='Count', title=\"Box Plot On Count\")\n",
    "axes[0][1].set(xlabel='Season', ylabel='Count',\n",
    "               title=\"Box Plot On Count Across Season\")\n",
    "axes[1][0].set(xlabel='Weekday', ylabel='Count',\n",
    "               title=\"Box Plot On Count Across Weekday\")\n",
    "axes[1][1].set(xlabel='Working Day', ylabel='Count',\n",
    "               title=\"Box Plot On Count Across Working Day\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Overall correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = hour_dask.corr()\n",
    "mask = np.array(corr)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 20)\n",
    "sns.heatmap(corr, mask=mask, vmax=.8, square=True, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Temperature and humidity and windspeed and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = hour_dask[[\"temp\", \"atemp\", \"casual\",\n",
    "                  \"registered\", \"hum\", \"windspeed\", \"cnt\"]].corr()\n",
    "mask = np.array(corr)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "sns.heatmap(corr, mask=mask, vmax=.8, square=True, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Distribution of wind, atemp, humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend & y axis label????\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(20, 5)\n",
    "\n",
    "# For demonstration purposes, a sample is taken from the dask dataframe\n",
    "hour_chart = hour_dask.sample(frac=0.1, replace=True).compute()\n",
    "\n",
    "fig1 = sns.regplot(x=\"atemp\", y=\"registered\",\n",
    "                   data=hour_chart, ax=ax1, fit_reg=False)\n",
    "fig1 = sns.regplot(x=\"atemp\", y=\"casual\",\n",
    "                   data=hour_chart, ax=ax1, fit_reg=False)\n",
    "fig1.set(xlabel='feeling temperature', ylabel='number of bikes')\n",
    "\n",
    "fig2 = sns.regplot(x=\"windspeed\", y=\"registered\",\n",
    "                   data=hour_chart, ax=ax2, fit_reg=False)\n",
    "fig2 = sns.regplot(x=\"windspeed\", y=\"casual\",\n",
    "                   data=hour_chart, ax=ax2, fit_reg=False)\n",
    "fig2.set(xlabel='windspeed', ylabel='number of bikes')\n",
    "\n",
    "fig3 = sns.regplot(x=\"hum\", y=\"registered\",\n",
    "                   data=hour_chart, ax=ax3, fit_reg=False)\n",
    "fig3 = sns.regplot(x=\"hum\", y=\"casual\", data=hour_chart, ax=ax3, fit_reg=False)\n",
    "fig3.set(xlabel='humidity', ylabel='number of bikes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Distribution of bikers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_no_outliers = hour_dask[np.abs(\n",
    "    hour[\"cnt\"] - hour[\"cnt\"].mean()) <= (3*hour[\"cnt\"].std())]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2)\n",
    "fig.set_size_inches(20, 10)\n",
    "sns.distplot(hour_chart[\"cnt\"], ax=axes[0])\n",
    "sns.distplot(np.log10(hour_no_outliers[\"cnt\"]), ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_test_split(df):\n",
    "    test = df[(df.yr == 1) & ((df.dteday.dt.month == 10) | (\n",
    "        df.dteday.dt.month == 11) | (df.dteday.dt.month == 12))]\n",
    "    train = df[:(len(df)-len(test))]\n",
    "    \n",
    "    return test, train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_fixed)\n",
    "\n",
    "# test = onehot_encode(test.drop(['dteday'], axis = 1))\n",
    "# train = onehot_encode(train.drop(['dteday'], axis = 1))\n",
    "\n",
    "test = test.drop(['dteday'], axis=1)\n",
    "train = train.drop(['dteday'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the linear regression model for the baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "def score_model(train, test, seed=123):\n",
    "    X_train = train.loc[:, (train.columns != 'cnt') &\n",
    "                        (train.columns != 'casual') &\n",
    "                        (train.columns != 'registered')]\n",
    "    y_train = train.loc[:, 'cnt']\n",
    "\n",
    "    X_test = test.loc[:, (test.columns != 'cnt') &\n",
    "                      (test.columns != 'casual') &\n",
    "                      (test.columns != 'registered')]\n",
    "    y_test = test.loc[:, 'cnt']\n",
    "\n",
    "    cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    pipeline = Pipeline([('linear_regression', LinearRegression())])\n",
    "    pipeline.fit(X_train.values, y_train.values)\n",
    "\n",
    "    training_score = pipeline.score(X_test, y_test)\n",
    "    print('R2 best features')\n",
    "    print('R2 from entire-dataset estimator: {:.3f}'.format(training_score))\n",
    "\n",
    "#     # Obtain scores and estimators from different splits and use the best one.\n",
    "#     scores = cross_validate(pipeline,\n",
    "#                             X_train, y_train,\n",
    "#                             scoring=['r2'],\n",
    "#                             cv=cv,\n",
    "#                             return_estimator=True)\n",
    "#     split_scores = [scores['estimator'][i].score(X_test, y_test)\n",
    "#                     for i in range(len(scores))]\n",
    "#     index_best = split_scores.index(max(split_scores))\n",
    "#     print('Best estimator R2 score: {:.3f}'.format(split_scores[index_best]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_multiple_2(train, test):\n",
    "\n",
    "    model = Pipeline([('linear_regression', LinearRegression(n_jobs=-1))])\n",
    "\n",
    "    splits = 1\n",
    "\n",
    "    y_test = test.loc[:, 'cnt']\n",
    "    predictions = []\n",
    "\n",
    "    for wd in [0, 1]:\n",
    "        for s in range(splits):\n",
    "            Xs_train = standardize_hour(train.loc[(train.workingday == wd) &\n",
    "                                                  (train.hr >= int(24*s/splits)) &\n",
    "                                                  (train.hr < int(24*(s+1)/splits)),\n",
    "                                                  (train.columns != 'cnt') &\n",
    "                                                  (train.columns != 'casual') &\n",
    "                                                  (train.columns != 'registered')])\n",
    "            ys_train = train.loc[(train.workingday == wd) &\n",
    "                                 (train.hr >= int(24*s/splits)) &\n",
    "                                 (train.hr < int(24*(s+1)/splits)), 'cnt']\n",
    "            Xs_test = standardize_hour(test.loc[(test.workingday == wd) &\n",
    "                                                (test.hr >= int(24*s/splits)) &\n",
    "                                                (test.hr < int(24*(s+1)/splits)),\n",
    "                                                (test.columns != 'cnt') &\n",
    "                                                (test.columns != 'casual') &\n",
    "                                                (test.columns != 'registered')])\n",
    "            ys_test = test.loc[(test.workingday == wd) &\n",
    "                               (test.hr >= int(24*s/splits)) &\n",
    "                               (test.hr < int(24*(s+1)/splits)), 'cnt']\n",
    "\n",
    "            reg_s = model\n",
    "            reg_s.fit(Xs_train, ys_train)\n",
    "            predictions.append(pd.DataFrame(cv_best_pred_2(\n",
    "                Xs_train, ys_train, Xs_test, ys_test, reg_s)))\n",
    "\n",
    "    y_pred = pd.DataFrame(columns=list(y_test))\n",
    "\n",
    "    y_pred = pd.concat(predictions).sort_index()\n",
    "\n",
    "#     for i in y_test.index.values:\n",
    "#         print((y_test[i], y_pred[i]))\n",
    "\n",
    "    return r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_multiple_3(train, test):\n",
    "\n",
    "    model = Pipeline([('linear_regression', LinearRegression(n_jobs=-1))])\n",
    "\n",
    "    splits = 1\n",
    "\n",
    "    y_test = test.loc[:, 'cnt']\n",
    "    predictions = []\n",
    "\n",
    "    for wd in [0, 1]:\n",
    "        for s in range(splits):\n",
    "            Xs_train = standardize_hour(train.loc[(train.workingday == wd) &\n",
    "                                                  (train.hr >= int(24*s/splits)) &\n",
    "                                                  (train.hr < int(24*(s+1)/splits)),\n",
    "                                                  (train.columns != 'cnt') &\n",
    "                                                  (train.columns != 'casual') &\n",
    "                                                  (train.columns != 'registered')])\n",
    "            ys_train = train.loc[(train.workingday == wd) &\n",
    "                                 (train.hr >= int(24*s/splits)) &\n",
    "                                 (train.hr < int(24*(s+1)/splits)), 'cnt']\n",
    "            Xs_test = standardize_hour(test.loc[(test.workingday == wd) &\n",
    "                                                (test.hr >= int(24*s/splits)) &\n",
    "                                                (test.hr < int(24*(s+1)/splits)),\n",
    "                                                (test.columns != 'cnt') &\n",
    "                                                (test.columns != 'casual') &\n",
    "                                                (test.columns != 'registered')])\n",
    "            ys_test = test.loc[(test.workingday == wd) &\n",
    "                               (test.hr >= int(24*s/splits)) &\n",
    "                               (test.hr < int(24*(s+1)/splits)), 'cnt']\n",
    "\n",
    "            reg_s = model\n",
    "            reg_s.fit(Xs_train, ys_train)\n",
    "            predictions.append(pd.DataFrame(cv_best_pred_2(\n",
    "                Xs_train, ys_train, Xs_test, ys_test, reg_s)))\n",
    "\n",
    "    y_pred = pd.DataFrame(columns=list(y_test))\n",
    "\n",
    "    y_pred = pd.concat(predictions).sort_index()\n",
    "\n",
    "#     for i in y_test.index.values:\n",
    "#         print((y_test[i], y_pred[i]))\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_best_pred(X_train, y_train, X_test, y_test, model):\n",
    "\n",
    "    cv = TimeSeriesSplit(n_splits=50)\n",
    "\n",
    "    models = cross_validate(model,\n",
    "                            X_train, y_train,\n",
    "                            scoring=['r2'],\n",
    "                            cv=cv,\n",
    "                            return_estimator=True)\n",
    "    preds = []\n",
    "    scores = []\n",
    "    for m in range(len(models['estimator'])):\n",
    "        preds.append(pd.Series([1 if (i < 0 or i > 1000)else math.ceil(\n",
    "            i)for i in models['estimator'][m].predict(X_test)], index=X_test.index.values))\n",
    "        scores.append(r2_score(y_test, preds[m]))\n",
    "    index_best = scores.index(max(scores))\n",
    "    return preds[index_best]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_best_pred_2(X_train, y_train, X_test, y_test, model):\n",
    "\n",
    "    cv = TimeSeriesSplit(n_splits=50)\n",
    "\n",
    "    models = cross_validate(model,\n",
    "                            X_train, y_train,\n",
    "                            scoring=['r2'],\n",
    "                            cv=cv,\n",
    "                            return_estimator=True)\n",
    "    preds = []\n",
    "    scores = []\n",
    "    for m in range(len(models['estimator'])):\n",
    "        preds.append(pd.Series([1 if (i < 0 or i > 1000) else math.ceil(\n",
    "            i)for i in models['estimator'][m].predict(X_train)], index=X_train.index.values))\n",
    "        scores.append(r2_score(y_train, preds[m]))\n",
    "    index_best = scores.index(max(scores))\n",
    "\n",
    "    pred = pd.Series([1 if (i < 0 or i > 1000) else math.ceil(\n",
    "        i)for i in models['estimator'][index_best].predict(X_test)], index=X_test.index.values)\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE1.1: Dropping temp and weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature variable is captured by the atemp variable, therefore we drop one of the two; in this case temperature.\n",
    "The workingday variable is also able to capture similar information as the weekday variable, and so we drop weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables\n",
    "dataset_FE1 = dataset_fixed.drop(['atemp', 'weekday'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE1)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE1.2: Dropping atemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables\n",
    "dataset_FE1 = dataset_fixed.drop(['atemp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE1)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE2: Grouping hours and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group hours based on pattern for casual users\n",
    "dataset_FE2 = dataset_fixed.drop(['temp', 'weekday'], axis=1)\n",
    "dataset_FE2.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2['hour'] = pd.cut(dataset_FE2['hr'], [-1, 6, 12, 17, 23],\n",
    "                             labels=[\"Early_Morning\", \"Morning\", \"Afternon\", \"Evening\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2.hour.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2[\"hour\"] = dataset_FE2[\"hour\"].astype('category').cat.codes\n",
    "dataset_FE2[\"hour\"] = dataset_FE2[\"hour\"].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2.hour.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2['atemp_level'] = pd.cut(dataset_FE2['atemp'], 3,\n",
    "                                    labels=[\"cold\", \"regular\", \"hot\"])\n",
    "dataset_FE2[\"atemp_level\"] = dataset_FE2[\"atemp_level\"].astype(\n",
    "    'category').cat.codes\n",
    "dataset_FE2[\"atemp_level\"] = dataset_FE2[\"atemp_level\"].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE2)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE3: Drop month but keep seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_month(df):\n",
    "    df = df.drop(['atemp', 'mnth'], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE3 = drop_month(dataset_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE3)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE4: Clustering weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKMeans(df, numberOfClusters=50):\n",
    "    kmeans = KMeans(n_clusters=numberOfClusters, random_state=123).fit(\n",
    "        df[['temp', 'hum', 'windspeed']])\n",
    "    df['cluster'] = kmeans.labels_\n",
    "    df[['cluster']] = df[['cluster']].astype('category')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE4 = getKMeans(dataset_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE4)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE5: Combining weather variabes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_weather(df):\n",
    "    df['temphum'] = df['hum']*df['temp']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE5 = combine_weather(dataset_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE5)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE6: External data: rush hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rush_hour(row):\n",
    "    if (row['hr'] >= 7 and row['hr'] <= 9and row['workingday'] == 1):\n",
    "        return 1\n",
    "    elif (row['hr'] >= 17 and row['hr'] <= 19 and row['workingday'] == 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def add_rush_hour(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['rush_hour'] = df.apply(lambda row: rush_hour(row), axis=1)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE6 = add_rush_hour(dataset_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE6)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FE7: GP Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_features(df):\n",
    "    X = df.loc[:, (df.columns != 'cnt') & (df.columns != 'casual') & (\n",
    "        df.columns != 'registered') & (df.columns != 'dteday')]\n",
    "    y = df.loc[:, 'cnt']\n",
    "\n",
    "    function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                    'abs', 'neg', 'inv', 'max', 'min', 'sin', 'cos', 'tan']\n",
    "    gp = SymbolicTransformer(generations=10,\n",
    "                             population_size=1000,\n",
    "                             hall_of_fame=100,\n",
    "                             n_components=12,\n",
    "                             function_set=function_set,\n",
    "                             parsimony_coefficient=0.0005,\n",
    "                             max_samples=0.9, verbose=0,\n",
    "                             random_state=123, n_jobs=-1)\n",
    "    gp.fit(pd.get_dummies(X), y)\n",
    "    gp_features = gp.transform(pd.get_dummies(X))\n",
    "\n",
    "    feats = pd.DataFrame(gp_features)\n",
    "    feats.columns = ['gp{}'.format(i)\n",
    "                     for i in range(len(list(feats)))]\n",
    "    df = pd.concat([df, feats], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_FE7 = gp_features(dataset_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_FE7)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eng = getKMeans(drop_month(add_rush_hour(gp_features(dataset_fixed))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = custom_train_test_split(dataset_eng)\n",
    "\n",
    "test = onehot_encode(test.drop(['dteday'], axis=1))\n",
    "train = onehot_encode(train.drop(['dteday'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multiple_2(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eng.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
